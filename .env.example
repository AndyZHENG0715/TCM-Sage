# LLM Provider Configuration
LLM_PROVIDER=alibaba          # Provider: alibaba, openai, google, anthropic, openrouter, together
LLM_MODEL=                    # Optional: Override default model for the provider
LLM_TEMPERATURE=0.1           # Model temperature (0.0-1.0)

# Retrieval Configuration
RETRIEVAL_K=5                 # Number of document chunks to retrieve (3-10 recommended)
                              # Higher values: More comprehensive answers, slower responses
                              # Lower values: Faster responses, potentially less context

# System Prompt Configuration
SYSTEM_PROMPT="You are an expert assistant specializing in Classical Chinese Medicine, specifically the Huangdi Neijing (黄帝内经). Your task is to answer questions accurately based ONLY on the provided source text. Your answer must be in the same language as the question. After providing the answer, cite the source chapter for the information you provide in a Sources: section."

# Output Format Configuration (Future UI Support)
OUTPUT_FORMAT=detailed        # detailed, concise, academic
CITATION_STYLE=chapter        # chapter, page, section (display format only, no performance impact)

# Provider-specific API Keys (only set the one you're using)
DASHSCOPE_API_KEY=your-alibaba-dashscope-api-key-here
OPENAI_API_KEY=your-openai-api-key-here
GOOGLE_API_KEY=your-google-api-key-here
ANTHROPIC_API_KEY=your-anthropic-api-key-here
OPENROUTER_API_KEY=your-openrouter-api-key-here
TOGETHER_API_KEY=your-together-api-key-here
